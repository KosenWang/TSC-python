{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "import torch.utils.data as Data\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils.csv as csv\n",
    "from models.transformer import TransformerRegression\n",
    "import utils.validation as val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "PATH='D:\\\\Deutschland\\\\FUB\\\\master_thesis\\\\data\\\\gee\\\\output'\n",
    "DATA_DIR = os.path.join(PATH, 'monthly_mean')\n",
    "LABEL_CSV = '7_classes.csv'\n",
    "\n",
    "label_path = os.path.join(PATH, LABEL_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.01\n",
    "EPOCH = 100\n",
    "SEED = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for Transformer model\n",
    "src_size = 8000\n",
    "tgt_size = 101\n",
    "d_model = 8\n",
    "nhead = 4\n",
    "num_layers = 1\n",
    "dim_feedforward = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_tensor(x_data:np.ndarray, y_data:np.ndarray):\n",
    "    # x_data = x_data.T\n",
    "    # y_data = y_data.T\n",
    "    x_set = torch.from_numpy(x_data)\n",
    "    y_set = torch.from_numpy(y_data)\n",
    "    return x_set, y_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(x_set:Tensor, y_set:Tensor, batch_size:int, seed:int):\n",
    "    dataset = Data.TensorDataset(x_set, y_set)\n",
    "    # split dataset\n",
    "    size = len(dataset)\n",
    "    train_size, val_size = round(0.8 * size), round(0.2 * size)\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    train_dataset, val_dataset = Data.random_split(dataset, [train_size, val_size], generator)\n",
    "    # # manually split dataset\n",
    "    # x_train = x_set[:444]\n",
    "    # y_train = y_set[:444]\n",
    "    # x_val = x_set[444:]\n",
    "    # y_val = y_set[444:]\n",
    "    # train_dataset = Data.TensorDataset(x_train, y_train)\n",
    "    # val_dataset = Data.TensorDataset(x_val, y_val)\n",
    "    # data_loader\n",
    "    train_loader = Data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "    val_loader = Data.DataLoader(val_dataset,batch_size=32, shuffle=True,num_workers=2)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:nn.Module, epoch:int):\n",
    "    total_step = len(train_loader)\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.t().to(device)\n",
    "        labels = labels.t().to(device)\n",
    "        # forward pass\n",
    "        outputs = model(inputs, labels)\n",
    "        loss = criterion(outputs, labels/100.)\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # record training loss\n",
    "        if i % 40 == 0:\n",
    "            print('Epoch[{}/{}],Step[{}/{}],Loss:{:.4f}'\n",
    "            .format(epoch+1,EPOCH,i+40,total_step,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model:nn.Module):\n",
    "    model.eval()\n",
    "    good_pred = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in val_loader:\n",
    "            inputs = inputs.t().to(device)\n",
    "            labels = labels.t().to(device)\n",
    "            outputs = model(inputs, labels)\n",
    "            print(outputs)\n",
    "            print(outputs.size())\n",
    "            good_pred += val.valid_num(labels/100., outputs)\n",
    "            total += labels.size(1)\n",
    "            break\n",
    "    print(f'Validation accuracy: {good_pred / total * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # dataset\n",
    "    x_data, y_data = csv.to_numpy(DATA_DIR, label_path)\n",
    "    x_set, y_set = numpy_to_tensor(x_data, y_data)\n",
    "    train_loader, val_loader = build_dataloader(x_set, y_set, BATCH_SIZE, SEED)\n",
    "    # model\n",
    "    model = TransformerRegression(src_size, tgt_size, d_model, nhead, num_layers, dim_feedforward).to(device)\n",
    "    # loss and optimizer\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), LR, momentum=0.99)\n",
    "    # train and validate model\n",
    "    print(\"Start training\")\n",
    "    for epoch in range(EPOCH):\n",
    "        train(model, epoch)\n",
    "        # validate(model)\n",
    "    # save model\n",
    "    # torch.save(model, '../outputs/model.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57200abac2ff18432c53e10587ceb364acdd46eebe90c6833204d1f95e2c9eff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
